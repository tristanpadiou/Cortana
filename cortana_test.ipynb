{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google_agent import Google_agent\n",
    "from deep_research import Deep_research_engine\n",
    "from pydantic_ai import Agent, RunContext\n",
    "from pydantic_ai.common_tools.tavily import tavily_search_tool\n",
    "from pydantic_ai.messages import ModelMessage\n",
    "from pydantic_ai.models.gemini import GeminiModel\n",
    "from pydantic_ai.providers.google_gla import GoogleGLAProvider\n",
    "from dotenv import load_dotenv\n",
    "from dataclasses import dataclass\n",
    "from datetime import datetime\n",
    "from pydantic import Field\n",
    "from google.oauth2.credentials import Credentials\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "import os\n",
    "from tavily import TavilyClient\n",
    "load_dotenv()\n",
    "google_api_key=os.getenv('google_api_key')\n",
    "tavily_key=os.getenv('tavily_key')\n",
    "pse=os.getenv('pse')\n",
    "openai_api_key=os.getenv('openai_api_key')\n",
    "tavily_client = TavilyClient(api_key=tavily_key)\n",
    "composio_api_key=os.getenv('composio_api_key')\n",
    "pydantic_llm=GeminiModel('gemini-2.0-flash', provider=GoogleGLAProvider(api_key=google_api_key))\n",
    "GEMINI_MODEL='gemini-2.0-flash'\n",
    "langchain_llm = ChatGoogleGenerativeAI(google_api_key=google_api_key, model=GEMINI_MODEL, temperature=0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from token_creator import get_creds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "creds=get_creds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# if os.path.exists(\"token.json\"):\n",
    "#     creds = Credentials.from_authorized_user_file(\"token.json\")\n",
    "# creds=Credentials.from_authorized_user_info(info={'refresh_token':\"\",\n",
    "#                                                   'client_id':\"\",\n",
    "#                                                   'client_secret':\"\"},\n",
    "#                                                   scopes=[\"https://mail.google.com/\", \"https://www.googleapis.com/auth/calendar\", \"https://www.googleapis.com/auth/cloud-platform\", \"https://www.googleapis.com/auth/contacts\", \"https://www.googleapis.com/auth/tasks\", \"https://www.googleapis.com/auth/generative-language.retriever\"])\n",
    "api_keys={\n",
    "    'google_api_key':google_api_key,\n",
    "    'tavily_key':tavily_key,\n",
    "    'pse':pse,\n",
    "    'creds':creds,\n",
    "    'openai_api_key':openai_api_key,\n",
    "    'composio_key':composio_api_key\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Message_state:\n",
    "    messages: list[ModelMessage]\n",
    "\n",
    "@dataclass\n",
    "class Deps:\n",
    "    deep_research_output: dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cortana_agent:\n",
    "    def __init__(self, api_keys:dict):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            \n",
    "            api_keys (dict): The API keys to use as a dictionary\n",
    "        \"\"\"\n",
    "        GEMINI_MODEL='gemini-2.0-flash'\n",
    "        \n",
    "        pydantic_llm=GeminiModel('gemini-2.0-flash', provider=GoogleGLAProvider(api_key=api_keys['google_api_key']))\n",
    "        openai_llm=ChatOpenAI(api_key=api_keys['openai_api_key'])\n",
    "        langchain_llm = ChatGoogleGenerativeAI(google_api_key=api_keys['google_api_key'], model=GEMINI_MODEL, temperature=0.3)\n",
    "        # tools\n",
    "        llms={'pydantic_llm':pydantic_llm,\n",
    "              'langchain_llm':langchain_llm,\n",
    "              'openai_llm':openai_llm}\n",
    "        deep_research_engine=Deep_research_engine(pydantic_llm,api_keys)\n",
    "        \n",
    "        def google_agent_tool(query:str):\n",
    "            \"\"\"\n",
    "            Use this tool to interact with the google agent, which can, search for images, manage the user's calendar, emails, google tasks, contacts, and more.\n",
    "            Args:\n",
    "                query (str): The entire query related to the google agent and its capabilities\n",
    "            Returns:\n",
    "                str: The response from the google agent\n",
    "            \"\"\"\n",
    "            google_agent=Google_agent(llms,api_keys)\n",
    "            try:\n",
    "                res=google_agent.chat(query)\n",
    "                return res\n",
    "            except Exception as e:\n",
    "                return f\"An error occurred: {e}\"\n",
    "       \n",
    "\n",
    "        async def search_and_question_answering_tool(ctx: RunContext[Deps], query:str):\n",
    "            \"\"\"\n",
    "            Use this tool to do a deep research on a topic, to gather detailed informations and data, answer_questions from the deep research results or do a quick research if the answer is not related to the deep research.\n",
    "            Args:\n",
    "                query (str): The query related to the search_and_question_answering_tool and its capabilities\n",
    "                \n",
    "\n",
    "            Returns:\n",
    "                str: The response from the search_and_question_answering_tool\n",
    "            \"\"\"\n",
    "            @dataclass\n",
    "            class Route:\n",
    "                answer: str = Field(default_factory=None,description=\"the answer to the question if the question is related to the deep research\")\n",
    "                route: str = Field(description=\"the route, either deep_research or answer_question, or quick_research\")\n",
    "            agent=Agent(pydantic_llm, output_type=Route, instructions=\"you are a router/question answering agent, you are given a query and you need to decide what to do based on the information provided\")\n",
    "            response= agent.run_sync(f\"based on the query: {query}, and the information provided: {ctx.deps.deep_research_output if ctx.deps.deep_research_output else ''} either answer the question or if the answer is not related to the information provided or need more information return 'quick_research' or 'deep_research'\")\n",
    "            route=response.output.route\n",
    "            if route=='deep_research':\n",
    "                response=deep_research_engine.chat(query)\n",
    "                ctx.deps.deep_research_output=response\n",
    "                return response\n",
    "            elif route=='answer_question':\n",
    "                return response.output.answer\n",
    "            elif route=='quick_research':\n",
    "                quick_research_agent=Agent(pydantic_llm, tools=[tavily_search_tool(api_keys['tavily_key'])], instructions=\"do a websearch based on the query\")\n",
    "                result= quick_research_agent.run_sync(query)\n",
    "                return result.output\n",
    "\n",
    "        def get_current_time_tool():\n",
    "            \"\"\"\n",
    "            Use this tool to get the current time.\n",
    "            Returns:\n",
    "                str: The current time in a formatted string\n",
    "            \"\"\"\n",
    "        \n",
    "            return f\"The current time is {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\"\n",
    "        @dataclass\n",
    "        class cortana_output:\n",
    "            full_answer: str = Field(description=\"the full answer to the user's query with output from the tools if tools are used\")\n",
    "            voice_answer: str = Field(description=\"if the answer is longer than 100 words, return a shorter answer to the user's query for the voice assistant else return the full answer\")\n",
    "        self.agent=Agent(pydantic_llm, output_type=cortana_output, tools=[google_agent_tool, search_and_question_answering_tool, get_current_time_tool], instructions=\"you are Cortana, a helpful assistant that can help with a wide range of tasks,\\\n",
    "                          you can use the tools provided to you to help the user with their queries, ask how you can help the user\")\n",
    "        self.memory=Message_state(messages=[])\n",
    "        self.deps=Deps(deep_research_output={})\n",
    "    def chat(self, query:str):\n",
    "        result=self.agent.run_sync(query, deps=self.deps, message_history=self.memory.messages)\n",
    "        self.memory.messages=result.all_messages()\n",
    "        return result.output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cortana_agent=Cortana_agent(api_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\trist\\OneDrive\\Desktop\\important\\ai_portfolio\\Cortana\\.venv\\Lib\\site-packages\\composio\\client\\collections.py:1183: UserWarning: Using all actions of an app is not recommended for production.Learn more: https://docs.composio.dev/patterns/tools/use-tools/use-specific-actions\n",
      "\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cortana_agent.__init__.<locals>.cortana_output(full_answer='I have sent a picture of a cat to padioutristan@gmail.com', voice_answer='I have sent a picture of a cat to padioutristan@gmail.com')\n"
     ]
    }
   ],
   "source": [
    "res=cortana_agent.chat('send a picture of a cat to padioutristan@gmail.com')\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cortana_agent.memory.messages"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
