{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google_agent import Google_agent\n",
    "from deep_research import Deep_research_engine\n",
    "from pydantic_ai import Agent, RunContext\n",
    "from pydantic_ai.common_tools.tavily import tavily_search_tool\n",
    "from pydantic_ai.messages import ModelMessage\n",
    "from pydantic_ai.models.gemini import GeminiModel\n",
    "from pydantic_ai.providers.google_gla import GoogleGLAProvider\n",
    "from dotenv import load_dotenv\n",
    "from dataclasses import dataclass\n",
    "from datetime import datetime\n",
    "from pydantic import Field\n",
    "from google.oauth2.credentials import Credentials\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "import os\n",
    "from tavily import TavilyClient\n",
    "load_dotenv()\n",
    "google_api_key=os.getenv('google_api_key')\n",
    "tavily_key=os.getenv('tavily_key')\n",
    "pse=os.getenv('pse')\n",
    "tavily_client = TavilyClient(api_key=tavily_key)\n",
    "pydantic_llm=GeminiModel('gemini-2.0-flash', provider=GoogleGLAProvider(api_key=google_api_key))\n",
    "GEMINI_MODEL='gemini-2.0-flash'\n",
    "langchain_llm = ChatGoogleGenerativeAI(google_api_key=google_api_key, model=GEMINI_MODEL, temperature=0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from token_creator import get_creds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "creds=get_creds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# if os.path.exists(\"token.json\"):\n",
    "#     creds = Credentials.from_authorized_user_file(\"token.json\")\n",
    "creds=Credentials.from_authorized_user_info(info={'refresh_token':\"\",\n",
    "                                                  'client_id':\"\",\n",
    "                                                  'client_secret':\"\"},\n",
    "                                                  scopes=[\"https://mail.google.com/\", \"https://www.googleapis.com/auth/calendar\", \"https://www.googleapis.com/auth/cloud-platform\", \"https://www.googleapis.com/auth/contacts\", \"https://www.googleapis.com/auth/tasks\", \"https://www.googleapis.com/auth/generative-language.retriever\"])\n",
    "api_keys={\n",
    "    'google_api_key':google_api_key,\n",
    "    'tavily_key':tavily_key,\n",
    "    'pse':pse,\n",
    "    'creds':creds\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Message_state:\n",
    "    messages: list[ModelMessage]\n",
    "\n",
    "@dataclass\n",
    "class Deps:\n",
    "    deep_research_output: dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cortana_agent:\n",
    "    def __init__(self, api_keys:dict):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            \n",
    "            api_keys (dict): The API keys to use as a dictionary\n",
    "        \"\"\"\n",
    "        pydantic_llm=GeminiModel('gemini-2.0-flash', provider=GoogleGLAProvider(api_key=api_keys['google_api_key']))\n",
    "        GEMINI_MODEL='gemini-2.0-flash'\n",
    "        langchain_llm = ChatGoogleGenerativeAI(google_api_key=api_keys['google_api_key'], model=GEMINI_MODEL, temperature=0.3)\n",
    "        # tools\n",
    "        google_agent=Google_agent(langchain_llm,api_keys)\n",
    "        deep_research_engine=Deep_research_engine(pydantic_llm,api_keys)\n",
    "        \n",
    "        def google_agent_tool(query:str):\n",
    "            \"\"\"\n",
    "            Use this tool to interact with the google agent, which can, search for images, manage the user's calendar, emails, google tasks, contacts, and more.\n",
    "            Args:\n",
    "                query (str): The entire query related to the google agent and its capabilities\n",
    "            Returns:\n",
    "                str: The response from the google agent\n",
    "            \"\"\"\n",
    "            return google_agent.chat(query)\n",
    "\n",
    "       \n",
    "\n",
    "        async def search_and_question_answering_tool(ctx: RunContext[Deps], query:str):\n",
    "            \"\"\"\n",
    "            Use this tool to do a deep research on a topic, to gather detailed informations and data, answer_questions from the deep research results or do a quick research if the answer is not related to the deep research.\n",
    "            Args:\n",
    "                query (str): The query related to the search_and_question_answering_tool and its capabilities\n",
    "                \n",
    "\n",
    "            Returns:\n",
    "                str: The response from the search_and_question_answering_tool\n",
    "            \"\"\"\n",
    "            @dataclass\n",
    "            class Route:\n",
    "                answer: str = Field(default_factory=None,description=\"the answer to the question if the question is related to the deep research\")\n",
    "                route: str = Field(description=\"the route, either deep_research or answer_question, or quick_research\")\n",
    "            agent=Agent(pydantic_llm, result_type=Route, system_prompt=\"you are a router/question answering agent, you are given a query and you need to decide what to do based on the information provided\")\n",
    "            response=await agent.run(f\"based on the query: {query}, and the information provided: {ctx.deps.deep_research_output if ctx.deps.deep_research_output else ''} either answer the question or if the answer is not related to the information provided or need more information, return 'quick_research' or 'deep_research'\")\n",
    "            route=response.data.route\n",
    "            if route=='deep_research':\n",
    "                response=await deep_research_engine.chat(query)\n",
    "                ctx.deps.deep_research_output=response\n",
    "                return response\n",
    "            elif route=='answer_question':\n",
    "                \n",
    "                return response.data.answer\n",
    "            elif route=='quick_research':\n",
    "                quick_research_agent=Agent(pydantic_llm, tools=[tavily_search_tool(api_keys['tavily_key'])], system_prompt=\"do a websearch based on the query\")\n",
    "                result=await quick_research_agent.run(query)\n",
    "                return result.data\n",
    "\n",
    "        def get_current_time_tool():\n",
    "            \"\"\"\n",
    "            Use this tool to get the current time.\n",
    "            Returns:\n",
    "                str: The current time in a formatted string\n",
    "            \"\"\"\n",
    "        \n",
    "            return f\"The current time is {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\"\n",
    "        \n",
    "\n",
    "        self.agent=Agent(pydantic_llm, tools=[google_agent_tool, search_and_question_answering_tool, get_current_time_tool], system_prompt=\"you are Cortana, a helpful assistant that can help with a wide range of tasks,\\\n",
    "                          you can use the tools provided to you to help the user with their queries\")\n",
    "        self.memory=Message_state(messages=[])\n",
    "        self.deps=Deps(deep_research_output={})\n",
    "    async def chat(self, query:str):\n",
    "        result=await self.agent.run(query, deps=self.deps, message_history=self.memory.messages)\n",
    "        self.memory.messages=result.all_messages()\n",
    "        return result.data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "cortana_agent=Cortana_agent(api_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK. Here are the 5 latest emails in your inbox:\n",
      "* From: Vessi <hello@vessi.com> - Subject: ðŸ’§ Limited-edition spring styles are here\n",
      "* From: A10 Kitchen <promotions@spotapps.co> - Subject: A10 Kitchen\n",
      "* From: LinkedIn <messages-noreply@linkedin.com> - Subject: Tammy Wolfson sent you a message 3 days ago\n",
      "* From: Apollo <hello@mail.apollo.io> - Subject: âš¡ Prospect anywhere with the Apollo Chrome Extension\n",
      "* From: Glassdoor Jobs <noreply@glassdoor.com> - Subject: Director, Machine Learning Engineering at Warner Bros. Discovery and 7 more jobs in New York, NY for you. Apply Now.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(await cortana_agent.chat('get my mail'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ModelRequest(parts=[SystemPromptPart(content='you are Cortana, a helpful assistant that can help with a wide range of tasks,                          you can use the tools provided to you to help the user with their queries', timestamp=datetime.datetime(2025, 4, 16, 16, 0, 50, 748294, tzinfo=datetime.timezone.utc), dynamic_ref=None, part_kind='system-prompt'), UserPromptPart(content='what can you tell me about the moon landing', timestamp=datetime.datetime(2025, 4, 16, 16, 0, 50, 748302, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'),\n",
       " ModelResponse(parts=[ToolCallPart(tool_name='search_and_question_answering_tool', args={'query': 'what happened during the moon landing'}, tool_call_id='pyd_ai_3b5c865126574fb6ba82ffaada33ef31', part_kind='tool-call')], model_name='gemini-2.0-flash', timestamp=datetime.datetime(2025, 4, 16, 16, 0, 51, 428864, tzinfo=datetime.timezone.utc), kind='response'),\n",
       " ModelRequest(parts=[ToolReturnPart(tool_name='search_and_question_answering_tool', content='The Apollo 11 mission successfully landed on the moon on July 20, 1969. Neil Armstrong and Buzz Aldrin became the first humans to walk on the lunar surface. They collected samples, planted a flag, and conducted experiments. The mission was a major achievement for the United States and a significant moment in human history.\\n', tool_call_id='pyd_ai_3b5c865126574fb6ba82ffaada33ef31', timestamp=datetime.datetime(2025, 4, 16, 16, 0, 54, 606396, tzinfo=datetime.timezone.utc), part_kind='tool-return')], kind='request'),\n",
       " ModelResponse(parts=[TextPart(content='The Apollo 11 mission successfully landed on the moon on July 20, 1969. Neil Armstrong and Buzz Aldrin became the first humans to walk on the lunar surface. They collected samples, planted a flag, and conducted experiments. The mission was a major achievement for the United States and a significant moment in human history.\\n', part_kind='text')], model_name='gemini-2.0-flash', timestamp=datetime.datetime(2025, 4, 16, 16, 0, 55, 291480, tzinfo=datetime.timezone.utc), kind='response')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cortana_agent.memory.messages"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
